from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import sys
import pandas as pd
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from kiwipiepy import Kiwi
from kiwipiepy.utils import Stopwords
import re
import torch
import tiktoken


tokenizer = AutoTokenizer.from_pretrained("Kdogs/klue-finetuned-squad_kor_v1")

model = AutoModelForQuestionAnswering.from_pretrained("Kdogs/klue-finetuned-squad_kor_v1")

question = sys.stdin.readline()

data = pd.read_csv('/home/t23108/svr/JH_PRACTICE/AI/crawling/notification.csv')

def clean_content(content):
    lines = content.split('\n')
    new_lines = [line for line in lines if line.strip()]  # ë¹„ì–´ ìˆì§€ ì•Šì€ ì¤„ë§Œ ì„ íƒ
    new_content = "\n".join(new_lines)
    new_str = re.sub('[^A-Za-z0-9ê°€-í£\s\-,(\).:]', '', new_content)
    return new_str

def get_answer(question, context):
    inputs = tokenizer(question, context, return_tensors="pt")
    
    with torch.no_grad():
        outputs = model(**inputs)
        
    answer_start_index = outputs.start_logits.argmax()
    answer_end_index = outputs.end_logits.argmax()
    
    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]
    answer = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)
    
    return answer

def Find_Title(df, max_score):
    same_score = df.loc[df['ì ìˆ˜'] == max_score, ['ì œëª©']]
    top_score_list = same_score['ì œëª©'].tolist()
    return top_score_list

def Similar(noti_list,question):
    tfidf_vectorizer = TfidfVectorizer()
    noti_list.append(question)  # ì…ë ¥ ë¬¸ì¥ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    
    # ë¬¸ì¥ë“¤ì„ ë²¡í„°í™”
    tfidf_matrix = tfidf_vectorizer.fit_transform(noti_list)
    
    # ì…ë ¥ ë¬¸ì¥ê³¼ ë‹¤ë¥¸ ë¬¸ì¥ë“¤ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ ë†’ì€ ìƒìœ„ 3ê°œ ë¬¸ì¥ì˜ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    top3_indices = similarity_scores.argsort()[0][-3:][::-1]
    
    # ìƒìœ„ 3ê°œ ë¬¸ì¥ ë°˜í™˜
    top3_sentences = [noti_list[i] for i in top3_indices]
    
    return top3_sentences

def create_chunks(text, chunk_size, overlap):
    tt_encoding = tiktoken.get_encoding("gpt2")
    tokens = tt_encoding.encode(text)
    total_tokens = len(tokens)
    
    chunks = []
    start = 0
    while start < total_tokens:
        end = start + chunk_size
        if end > total_tokens:
            end = total_tokens
        chunk = tokens[start:end]
        chunk_text = tt_encoding.decode(chunk)
        chunks.append(chunk_text)
        start = end - overlap

        if end == total_tokens:
            break

    return chunks

def main(question, data):
    kiwi = Kiwi(model_type='sbg', typos='basic')
    stopwords = Stopwords()
    
    tokens = kiwi.tokenize(question,stopwords=stopwords)
    
    token_list = []
    
    data['ì ìˆ˜'] = 0
    
    for i in tokens:
        if i[1] == 'NNG' or i[1] =='NNP' or i[1] == 'SL':
            token_list.append(i[0])
            for j in range(len(data)):
                if i[0] in data.loc[j]['ì œëª©']:
                    data.loc[j,'ì ìˆ˜'] += 1

    chunk_size = 500
    overlap = 10
    chat_response_list = []

    if int(data.loc[data['ì ìˆ˜'].idxmax()]['ì ìˆ˜']) > 0 :
        max_value = max(data['ì ìˆ˜'])
        if ((data['ì ìˆ˜'] == max_value).sum()) == 1:
            processed_message = "ğŸ“Œ  {0} í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ë‚´ìš©ì…ë‹ˆë‹¤.".format(token_list)
            processed_messange_2 = f"âœ¨  ê³µì§€ì œëª© : [{data.loc[data['ì ìˆ˜'].idxmax()]['ì œëª©']}]âœ¨"
            small_content = clean_content(data.iloc[data['ì ìˆ˜'].idxmax()]['content'])
  
            processed_link = data.loc[data['ì ìˆ˜'].idxmax()]['url']
            result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'
            token_lenth = str(len(tokenizer.tokenize(small_content)))        
 
            if len(tokenizer.tokenize(small_content)) > 512:
                chunks = create_chunks(small_content, chunk_size, overlap)
                for chunk in chunks:
                    if all(index in chunk for index in token_list):
                        chat_response_list.append("-" + get_answer(question, chunk) + "\n")
                    else:
                        pass
                
                chatBotMessage = f"ğŸ‘‰ ChatGCTê°€ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤. <br>â—ï¸{chat_response_list} â—ï¸"
                processed_link = data.loc[data['ì ìˆ˜'].idxmax()]['url']
                result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'
                print(processed_message+ "<br><br>" + chatBotMessage + "<br><br>" +processed_messange_2 +"<br><br>" + "<br><br>"+ result)
              
            else:
                chat_response = get_answer(question,small_content)
                chatBotMessage = f"ğŸ‘‰ ChatGCTê°€ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤. <br>â—ï¸{chat_response} â—ï¸"
                processed_link = data.loc[data['ì ìˆ˜'].idxmax()]['url']
                result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'
                print(processed_message+ "<br><br>"+chatBotMessage + "<br><br>" +processed_messange_2 + "<br><br>" +  "<br><br>"+ result)
        else:
            processed_message = "ğŸ“Œ  {0} í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ë‚´ìš©ì´ ë‹¤ìˆ˜ì…ë‹ˆë‹¤".format(token_list)
            noti_list = Find_Title(data,max_value)
            similar_list = Similar(noti_list,question)
            
            for i in range(len(data['ì œëª©'])):
                if data.iloc[i]['ì œëª©'] == similar_list[0]:
                    top_similar = data.iloc[i]
            
            processed_messange_2 = f"âœ¨ ìœ ì‚¬ë„ ë¶„ì„ê²°ê³¼ [{top_similar['ì œëª©']}] ê³µì§€ì‚¬í•­ì´ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ìŠµë‹ˆë‹¤!! âœ¨ "
            small_content = clean_content(top_similar['content'])

            processed_link = top_similar['url']
            result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'

           
            if len(tokenizer.tokenize(small_content)) > 512:
                chunks = create_chunks(small_content, chunk_size, overlap)
                for chunk in chunks:
                    if all(index in chunk for index in token_list):
                        chat_response_list.append("-" + get_answer(question, chunk) + "\n")
                    else:
                        pass
                    
                chatBotMessage = f"ğŸ‘‰ ChatGCTê°€ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤. <br>â—ï¸{chat_response_list} â—ï¸"
                processed_link = data.loc[data['ì ìˆ˜'].idxmax()]['url']
                result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'
                print(processed_message+ "<br><br>" + chatBotMessage + "<br><br>" +processed_messange_2 + "<br><br>" + "<br><br>"+ result)
            
            else:
                chat_response = get_answer(question,small_content)
                chatBotMessage = f"ğŸ‘‰ ChatGCTê°€ ì°¾ì€ ì •ë³´ì…ë‹ˆë‹¤. <br>â—ï¸{chat_response} â—ï¸"
                processed_link = top_similar['url']
                result = f'<a href="{processed_link}" target="_blank"><img src="https://www.gachon.ac.kr/sites/kor/images/sub/slogan_1.png" alt="ë§í¬ ì´ë¯¸ì§€"></a>'
                print(processed_message+ "<br><br>"+ chatBotMessage + "<br><br>" + processed_messange_2 + "<br><br>" + "<br><br>"+ result )
    else:
        processed_message = "ğŸ“Œ  ì§ˆë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê³µì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.ğŸ˜­ <br> âœ”ï¸ìˆ˜ê°•ì‹ ì²­ âœ”ï¸í•™ì‚¬ê³µì§€ ê´€ë ¨ ë‹¤ë¥¸ ê³µì§€ë¥¼ ë¬¼ì–´ë´ì£¼ì‹œë©´ ì°¾ì•„ë³¼ê²Œìš”!ğŸ˜†"
        print(processed_message)
    

main(question, data)
